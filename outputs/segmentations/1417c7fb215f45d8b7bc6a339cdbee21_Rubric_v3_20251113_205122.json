{
  "segmentation": {
    "sections": [
      {
        "section_id": "cover_1",
        "section_name": "COMP 200\nSummer Practice Report\nUmut Kadıoğlu\n042201104\n07.07.2025- 15.08.2025, 29 Workdays\nSubmitted: 28.09.2025\nMEF University\n_________________\nComputer Engineering Program",
        "content": "COMP 200\nSummer Practice Report\nUmut Kadıoğlu\n042201104\n07.07.2025- 15.08.2025, 29 Workdays\nSubmitted: 28.09.2025\nMEF University\n_________________\nComputer Engineering Program",
        "start_idx": 0,
        "end_idx": 200,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "executive_summary_1",
        "section_name": "Executive Summary",
        "content": "Executive Summary\nLumnion Bilişim Teknolojileri is a software company operating in the InsurTech\nsector, focusing on developing actuarial and artificial intelligence–based solutions for the\ninsurance industry. The main engineering activities of the company include backend\ndevelopment with ASP.NET Core and Entity Framework Core, database management with\nSQL Server, and the integration of actuarial models and AI algorithms into scalable software\nplatforms used by insurance and reinsurance companies.\nDuring my internship, I was part of the CashFlow development team. My activities\nprogressed step by step: in the first two weeks, I mainly focused on self-learning through\nUdemy courses, observing senior developers, and handling small tasks such as minor fixes\nand migration checks. From the third week onwards, I started taking responsibility for\nbackend tasks, including:\n Developing the Save Rule endpoint, merging create and update operations into a\nunified, more maintainable API.\n Implementing enumeration functions in SQL (e.g., INT_TO_ENUM, ENUM_SIZE,\nREAD_FROM_TABLE) to support actuarial formulas.\n Integrating user-specific settings (delimiter, digit count, sample size, error\nthresholds) into backend services.\n Designing an endpoint to check Master Product–Indicator usage, ensuring relational\nintegrity.\n Debugging and resolving frequent errors such as NullReferenceException and bulk\ninsert issues.\n\nMy initial expectation was simply to improve my technical skills and gain exposure to\nreal-world projects. However, the outcomes went beyond that: by the end of my internship,\nI was handling general backend engineering tasks on my own and directly contributing to\nfeatures that improved system reliability. Daily stand-ups, sprint planning meetings, and\nweekly product/investor sessions also gave me insight into how a professional software\nteam organizes its workflow.\nOverall, I gained both technical and professional growth. I improved my coding skills in\nC#, SQL, and API design, learned to manage database migrations and error handling, and\nsaw how engineering decisions directly affect business outcomes. Beyond the technical side,\nI learned the value of self-directed learning, teamwork across different roles, and even\nexplored topics like ethical hacking with my senior mentor. This internship gave me not only\npractical experience but also the confidence and mindset required to continue developing as\na software engineer.",
        "start_idx": 203,
        "end_idx": 2291,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "contents_1",
        "section_name": "Contents",
        "content": "Contents\nExecutive Summary .................................................................................................. 2\nContents .................................................................................................................... 3\n1. Company and Sector (maximum ten pages) ........................................................ 4\na. Overview of the Company and Sector (maximum two pages) ......................... 4\nb. Organization of the Company (maximum two pages) ..................................... 5\nc. Production/Service System (maximum two pages) ......................................... 6\nd. Professional and Ethical Responsibilities of Engineers ................................... 8\n2. Summer Practice Description (maximum fifteen pages) .................................... 11\n3. Conclusions (maximum one page).................................................................... 16\na. Impact (minimum one page) ......................................................................... 14\nb. Team Work (maximum one page) ................................................................ 15\nc. Self-directed Learning (minimum one page) ................................................. 16\nReferences ............................................................................................................... 21\nAppendix 1: Daily Activity Tables .......................................................................... 22",
        "start_idx": 2294,
        "end_idx": 2990,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "company_sector_1",
        "section_name": "1. Company and Sector (maximum ten pages).\na. Overview of the Company and Sector (maximum two pages).\nCompany Information",
        "content": "1. Company and Sector (maximum ten pages).\na. Overview of the Company and Sector (maximum two pages).\nCompany Information\nThe company is Lumnion Bilişim Teknolojileri A.Ş., a privately held startup operating\nin the InsurTech sector Its full address is Ömer Avni Mahallesi, İnebolu Sokak,\nBeyoğlu/İstanbul, Türkiye, and its official website is https://www.lumnion.com. Founded\nwith the mission of bridging actuarial science with artificial intelligence, Lumnion defines\nitself as an AI-Driven End-to-End Insurance Pricing Platform.\nThe company has approximately 19–20 employees, with no blue-collar workers. Mr.\nEray leads the engineering division as Chief of Engineering, managing a team of nine\nengineers: four working on the Platform modules (Bee and Cheetah) and five on the\nCashFlow product.\nThe Platform\nLumnion’s solutions are structured under a comprehensive Platform that brings\ntogether different modules supporting insurers at every stage of the pricing process. This\nend-to-end platform allows insurance companies to integrate data preparation, actuarial\nmodeling, machine learning, rule engines, and reporting in one environment. It is designed\nto ensure transparency, regulatory compliance, and operational efficiency. (Lumnion, 2025)\nProducts and Modules\n Bee: A module focused on automated data preparation. It manages cleaning,\ntransformation, and premium calculations, reducing manual work for actuaries.\n Cheetah: A module dedicated to risk pricing and actuarial modeling, supporting\nadvanced statistical and machine learning methods such as GLM, GAM, XGBoost,\nand Random Forest. It ensures transparency by converting ML outputs into\ncoefficients and base prices.\n CashFlow: A new product still in development (and the one I contributed to during\nmy internship), designed to handle cash flow projections, actuarial modeling, and\nfinancial simulations for insurers.\nCustomers and Competitors\nLumnion serves both domestic and international clients, reflecting the global nature\nof the insurance technology sector. While the company has a strong presence in Turkey, it\nalso competes in international markets against well-known players such as Prophet, SAS,\nand Guidewire. Unlike these larger corporations, Lumnion differentiates itself with agility,\nmodular design, and AI-driven transparency.\nSector and Role\nThe company operates in the broader InsurTech / insurance software domain. This\nsector is rapidly expanding due to advances in big data, cloud solutions, and AI. Lumnion’s\nrole is to modernize risk pricing and insurance operations by combining actuarial expertise\nwith machine learning and scalable backend systems.\nIn summary, Lumnion positions itself as both a platform provider and a modeling partner,\ndelivering tools that improve accuracy, compliance, and efficiency in insurance decision-\nmaking.",
        "start_idx": 2993,
        "end_idx": 5290,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "company_organization_1",
        "section_name": "b. Organization of the Company (maximum two pages)\nOrganizational Structure",
        "content": "b. Organization of the Company (maximum two pages)\nOrganizational Structure\nLumnion Bilişim Teknolojileri operates with a streamlined and specialized\norganizational structure that reflects the needs of a technology and software company. The\nstructure is organic rather than mechanistic, meaning that communication between\ndepartments is highly flexible, decision-making is relatively decentralized, and teams\ncollaborate closely to achieve project goals. This approach allows the company to adapt\nquickly to client needs and to the rapidly evolving insurance technology sector.\nAt the top of the hierarchy, the General Manager / CEO (Cenk Tabakoğlu) oversees\nthe overall strategy and direction of the company. Reporting directly to the CEO are three\nmain departments:\n1. Technology and Development Department\nHead: Chief of Engineering (Eray)\nTeam: 9 engineers divided into two product groups:\nPlatform Team (4 engineers): Working on Bee and Cheetah modules.\nCashFlow Team (5 engineers): Developing the new CashFlow product.\nRoles and responsibilities:\nSoftware Engineers: Build and maintain back-end and front-end systems (.NET, SQL,\nAPIs).\nData Scientists / Actuarial Specialists: Develop predictive models, risk pricing\nalgorithms, and ensure compliance with actuarial principles.\nQuality Assurance/Test Engineers: Responsible for debugging, testing, and ensuring\nproduct stability.\nCollaboration: This department works directly with the analyst team to transform client\nrequirements into software features.\n2. Analysis and Client Relations Department\nHead: Chief Analyst (Aren)\nTeam: 5–6 analysts.\nRoles and responsibilities:\nConduct testing to ensure software aligns with actuarial and client requirements.\nAct as a bridge between clients and engineers, translating customer feedback into\ntechnical tasks.\nSupport customer communication during and after implementation.\nCollaboration: This group is critical for aligning technical outputs with client needs and\nensuring that the platform remains user-focused.\n3. Administration and Support Department\nHead: Director (Tayfun)\nRoles and responsibilities:\no Finance: Budgeting, payroll, and financial compliance.\no Human Resources: Recruitment, training, and employee development.\no Investor Relations: Maintaining transparent and regular communication\nwith stakeholders and investors.",
        "start_idx": 5293,
        "end_idx": 7408,
        "level": 2,
        "parent_id": "company_sector_1"
      },
      {
        "section_id": "interdepartmental_relationships_1",
        "section_name": "Interdepartmental Relationships",
        "content": "Interdepartmental Relationships\nThe Technology & Development team works closely with the Analyst team to ensure\nthat client requirements are accurately implemented in the platform.\nThe Administration department supports both major teams by handling finance, HR,\nand investor communications.\nThe startup’s organic structure ensures that even interns and junior engineers can\ndirectly collaborate with senior staff, while final approvals are made by department heads.\nOrganizational Chart (Textual Representation)\nGeneral Manager / CEO (Cenk Tabakoğlu)\n|\n| | |\nTechnology & Development Chief Analyst Administration & Support\n(Eray Alpan) (Aren Haddeler) (Tayfun Özdemir)\n| | |\nSoftware Engineers Analysis & Client HR, Finance, Investor\nData Scientists Relations Team. Relartions\nConclusion\nOverall, Lumnion’s organizational structure reflects an organic and collaborative\nmodel. This structure fosters innovation, allows cross-functional teamwork, and ensures\nflexibility in responding to client needs, regulatory requirements, and technological\nadvancements in the InsurTech sector.",
        "start_idx": 7411,
        "end_idx": 8499,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "production_service_1",
        "section_name": "c. Production/Service System (maximum two pages)\nService System Overview",
        "content": "c. Production/Service System (maximum two pages)\nService System Overview\nAs a software company, Lumnion Bilişim Teknolojileri does not operate a traditional\nmanufacturing process. Instead, its “production” system is the development, testing, and\ndeployment of actuarial and AI-based software solutions. This system is highly knowledge-\nintensive and requires collaboration between multiple departments. The service cycle\nintegrates technology development, business development, finance, customer relations, and\nquality assurance into an iterative process that continuously delivers value to insurance\ncompanies.\nMajor Components of the Service System\n1. Marketing & Sales\no Identify market trends and client needs in the insurance sector.\no Promote the Lumnion Platform and its modules (Bee, Cheetah, and\nCashFlow) to domestic and international clients.\no Gather requirements and feedback to feed into the product backlog.\n2. Technology & Development\no Core responsibility for backend/frontend software engineering, actuarial\nmodeling, and AI integration.\no Tasks are managed through Agile methodology (daily stand-ups, bi-weekly\nsprint planning).",
        "start_idx": 8502,
        "end_idx": 9740,
        "level": 2,
        "parent_id": "company_sector_1"
      },
      {
        "section_id": "production_service_2",
        "section_name": "o Engineers work on separate GitHub branches, developing features\nindependently.",
        "content": "o Engineers work on separate GitHub branches, developing features\nindependently.\n3. Finance & Administration\no Oversees budgeting, payroll, and licensing costs.\no Allocates resources for R&D and ensures transparency for investors.\n4. Customer Relations & Support\no Provides technical support, client onboarding, and training.\no Maintains continuous communication with clients to collect feedback.\n5. Purchasing & Logistics\no Ensures availability of cloud infrastructure (Microsoft Azure, AWS).\no Manages tools, licenses, and external vendor relationships (e.g., SQL Server,\nGitHub).\nFlow Chart of a Major Service (Software Development Cycle)\nCustomer Requirements\n↓\nBusiness Development & Analyst Team\n↓\nTechnical Analysis & Sprint Planning\n↓\nSoftware Design (System Architecture)\n↓\nCoding & Implementation (Feature Branches in GitHub)\n↓\nTesting & Quality Assurance (Unit Tests, Integration Tests)\n↓\nTester Approval & Code Review\n↓\nMerge into Release-Test Branch (Integration Environment)\n↓\nDeployment (Cloud / Customer Environment)\n↓\nCustomer Training & Support\n↓\nContinuous Feedback (Investor, Product, and Client Meetings)\n↓\nProduct Updates & Iterations",
        "start_idx": 9740,
        "end_idx": 11281,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "company_sector_1",
        "section_name": "3. Finance & Administration",
        "content": "o Oversees budgeting, payroll, and licensing costs.\no Allocates resources for R&D and ensures transparency for investors.\n4. Customer Relations & Support\no Provides technical support, client onboarding, and training.\no Maintains continuous communication with clients to collect feedback.\n5. Purchasing & Logistics\no Ensures availability of cloud infrastructure (Microsoft Azure, AWS).\no Manages tools, licenses, and external vendor relationships (e.g., SQL Server,\nGitHub).",
        "start_idx": 11544,
        "end_idx": 11905,
        "level": 2,
        "parent_id": "production_service_2"
      },
      {
        "section_id": "company_sector_2",
        "section_name": "Flow Chart of a Major Service (Software Development Cycle)",
        "content": "Flow Chart of a Major Service (Software Development Cycle)\nCustomer Requirements\n↓\nBusiness Development & Analyst Team\n↓\nTechnical Analysis & Sprint Planning\n↓\nSoftware Design (System Architecture)\n↓\nCoding & Implementation (Feature Branches in GitHub)\n↓\nTesting & Quality Assurance (Unit Tests, Integration Tests)\n↓\nTester Approval & Code Review\n↓\nMerge into Release-Test Branch (Integration Environment)\n↓\nDeployment (Cloud / Customer Environment)\n↓\nCustomer Training & Support\n↓\nContinuous Feedback (Investor, Product, and Client Meetings)\n↓\nProduct Updates & Iterations\n7",
        "start_idx": 11905,
        "end_idx": 12355,
        "level": 2,
        "parent_id": "production_service_2"
      },
      {
        "section_id": "company_sector_3",
        "section_name": "Performance of the Service System",
        "content": "Productive Elements: feature development, actuarial modeling, testing, merging,\ndeployment, training, and client support.\nNon-Productive Elements: delays in tester approvals, sprint extensions (sometimes by one\nweek), rework caused by unclear requirements, waiting for customer confirmation.\nPerformance of the Service System\nThe performance of Lumnion’s service system is measured by:\nReliability: accuracy and stability of actuarial models and backend services.\nEfficiency: delivering features within sprint timelines and reducing rework.\nCustomer Satisfaction: feedback gathered in weekly product meetings (Thursdays), investor\nmeetings (Tuesdays), and customer onboarding sessions.\nScalability: ability to process larger datasets, comply with global standards (IFRS 17,\nSolvency II), and expand to new international markets.",
        "start_idx": 12357,
        "end_idx": 12955,
        "level": 2,
        "parent_id": "production_service_2"
      },
      {
        "section_id": "company_sector_4",
        "section_name": "Planning, Forecasting, and Logistics Activities",
        "content": "Planning, Forecasting, and Logistics Activities\nPlanning: Managed through Agile. Each day begins with a daily stand-up at 9:00, and every\ntwo weeks a sprint planning meeting sets development priorities. Weekly product meetings\non Thursdays track progress across teams, while investor meetings on Tuesdays align\ntechnical and financial expectations.\nForecasting: Market trends and regulatory changes are analyzed to predict demand for new\nactuarial features.\nInventory: Unlike physical manufacturing, inventory at Lumnion consists of cloud capacity,\nsoftware licenses, and test datasets.\nLogistics: Primarily digital ensuring cloud environments remain secure, test and production\nsystems are synchronized, and deployment windows minimize customer downtime.",
        "start_idx": 12957,
        "end_idx": 13514,
        "level": 2,
        "parent_id": "production_service_2"
      },
      {
        "section_id": "conclusion_1",
        "section_name": "Conclusion",
        "content": "Conclusion\nThe production/service system at Lumnion is iterative, agile, and knowledge-based.\nInstead of physical goods, the company produces reliable actuarial software solutions. The\nuse of GitHub branch-based workflows, strict tester approvals, and release-test integration\nensures that only stable features reach the customer environment. Combined with\ncontinuous planning, forecasting, and feedback loops, this system enables Lumnion to adapt\nquickly to both technological advances and the evolving needs of the global insurance\nindustry.",
        "start_idx": 13516,
        "end_idx": 13994,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "company_sector_5",
        "section_name": "d. Professional and Ethical Responsibilities of Engineers (minimum one\npage)",
        "content": "d. Professional and Ethical Responsibilities of Engineers (minimum one\npage)\nFunctions of Engineers in the Company\nAt Lumnion Bilişim Teknolojileri, engineers are at the core of the company’s ability\nto deliver actuarial and AI-based solutions for the insurance industry. Their primary\nfunctions include:\n8\n\n Designing and developing back-end services and APIs using C# and ASP.NET Core.\n Building actuarial and statistical models with algorithms such as GLM, GAM, Random\nForest, and Gradient Boosting.\n Writing and optimizing SQL queries, managing database migrations, and integrating\nactuarial model data with financial datasets.\n Conducting debugging, unit testing, and error handling to ensure software quality.\n Collaborating with actuaries, analysts, and product managers to turn client\nrequirements into technical features.\n Maintaining cloud infrastructures (Azure, AWS) for scalability, performance, and\nsecurity.",
        "start_idx": 13995,
        "end_idx": 14705,
        "level": 2,
        "parent_id": "conclusion_1"
      },
      {
        "section_id": "company_sector_6",
        "section_name": "Professional Responsibilities",
        "content": "Professional Responsibilities\nThe professional responsibilities of engineers at Lumnion extend beyond simply\nwriting code. They are expected to:\n Deliver reliable, maintainable, and efficient code aligned with project requirements.\n Ensure actuarial models comply with Solvency II and IFRS 17 standards.\n Follow Agile practices—daily stand-ups, sprint planning, code reviews, and tester\napprovals.\n Document technical processes for traceability and team knowledge sharing.\n Respect the company’s GitHub workflow, where no code can be merged into the\nrelease-test branch without senior and tester approval. This process guarantees\naccountability and technical integrity.",
        "start_idx": 14707,
        "end_idx": 15303,
        "level": 2,
        "parent_id": "conclusion_1"
      },
      {
        "section_id": "company_sector_7",
        "section_name": "Ethical Responsibilities",
        "content": "Ethical Responsibilities\nBecause Lumnion operates in the intersection of finance, insurance, and software,\nevery technical decision carries ethical implications. The ethical responsibilities of engineers\ninclude:\n Integrity and Honesty: Results must be accurate and transparent. Manipulating\nmodels to produce misleading financial outcomes is strictly avoided.\n Confidentiality: Engineers protect sensitive financial and client data. During\ncustomer meetings, only senior staff (Alperen, Eray, Hüseyin, Aren) communicated\ndirectly, while others listened silently—an example of respecting information flow\nand confidentiality boundaries.\n Accountability: Every engineer is responsible for the quality of their work. If a\nfeature fails in testing, it must be corrected before merging into the release branch.\nResponsibility is never shifted to others.\n Fairness: Since the software influences insurance pricing, models must be designed\nto avoid unfair discrimination and bias. This is a critical ethical requirement in\nInsurTech.\n Sustainability: Engineers are encouraged to write clean and efficient code that will\nremain maintainable for years, minimizing wasted time and computational\nresources.\n9",
        "start_idx": 15305,
        "end_idx": 16215,
        "level": 2,
        "parent_id": "conclusion_1"
      },
      {
        "section_id": "company_sector_8",
        "section_name": "Professional and Ethical Standards in the Company",
        "content": "Professional and Ethical Standards in the Company\nAlthough Lumnion does not maintain a formal written Code of Ethics, ethical\nstandards are embedded in its culture:\n IEEE/ACM Software Engineering Code of Ethics principles are followed indirectly,\nfocusing on product quality, accountability, and public interest.\n Actuarial association guidelines influence how models are developed, ensuring they\nare transparent and not misleading.\n The company’s culture is open, warm, and highly human-centric. Even though it is a\nsmall startup, ethical awareness is strong: from the most junior intern to the CEO,\ncommunication is direct and respectful. This environment itself functions as an\nunwritten but effective code of conduct.",
        "start_idx": 16217,
        "end_idx": 16893,
        "level": 2,
        "parent_id": "conclusion_1"
      },
      {
        "section_id": "conclusion_2",
        "section_name": "Conclusion",
        "content": "Conclusion\nFrom my observation, engineers at Lumnion balance technical competence with\nethical awareness. Code cannot be pushed without senior review, ensuring accountability.\nSensitive information is handled carefully, with only authorized voices communicating\ndirectly with clients. Although the company does not have a formal written ethics code, its\npeople-oriented culture and professional practices ensure that ethical standards are upheld\nin every project. This balance of professionalism and ethical responsibility builds both the\ntrust of clients and the integrity of the engineering team.\n10",
        "start_idx": 16895,
        "end_idx": 17505,
        "level": 2,
        "parent_id": "conclusion_1"
      },
      {
        "section_id": "activity_analysis_1",
        "section_name": "2. Summer Practice Description (maximum fifteen pages)",
        "content": "2. Summer Practice Description (maximum fifteen pages)\nOverview of Activities\nDuring my internship at Lumnion Bilişim Teknolojileri, I worked on several\nengineering tasks that combined backend development, database management, and API\ndesign. Some tasks were purely technical and required precision, while others taught me\nbroader lessons about teamwork and communication in a professional environment. At\ntimes, I felt challenged—especially when debugging errors for hours—but these challenges\nbecame the most valuable learning opportunities.\nBelow is the main list of activities I performed, with explanations, challenges, and\nreflections.",
        "start_idx": 17506,
        "end_idx": 18255,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "activity_analysis_2",
        "section_name": "1. Development of the Save Rule Endpoint",
        "content": "1. Development of the Save Rule Endpoint\nOne of my first major assignments was to merge the Create and Update operations\ninto a single Save Rule endpoint. This task was technically complex because it required\nrestructuring existing code while ensuring data integrity.\n Technical Challenge: Handling null IDs and foreign key conflicts without breaking\nother parts of the system.\n Reflection: At the beginning, I was nervous about touching such a critical endpoint,\nbut with guidance from senior engineers I gained confidence.\n Learning Outcome: I improved my knowledge of ASP.NET Core and Entity\nFramework Core, and learned how atomic transactions can prevent cascading\nerrors.",
        "start_idx": 18257,
        "end_idx": 18985,
        "level": 2,
        "parent_id": "activity_analysis_1"
      },
      {
        "section_id": "activity_analysis_3",
        "section_name": "2. Enumeration Functions in SQL",
        "content": "2. Enumeration Functions in SQL\nI worked on SQL-based functions such as INT_TO_ENUM, ENUM_SIZE, and\nREAD_FROM_TABLE. These were essential for mapping categorical variables into actuarial\nmodels.\n Technical Challenge: The READ_FROM_TABLE function was especially difficult, since\nit required dynamic queries to handle variable row headers.\n Reflection: It was fascinating to see how abstract actuarial formulas could be\ntranslated into SQL logic. Debugging felt frustrating at times, but the moment it\nfinally worked was very rewarding.\n Learning Outcome: I learned to design flexible database functions and gained\nappreciation for how enumeration supports complex business rules.",
        "start_idx": 18987,
        "end_idx": 19743,
        "level": 2,
        "parent_id": "activity_analysis_1"
      },
      {
        "section_id": "activity_analysis_4",
        "section_name": "3. Entity Framework Core Migrations",
        "content": "3. Entity Framework Core Migrations\nI also worked on updating the database schema with new fields like Delimiter, Digit\nCount, and Sample Size.\n Technical Challenge: Migration errors such as invalid column names and locale\nmismatches often appeared during runtime.\n Reflection: These issues taught me patience—sometimes the solution was a single\nline of code, but it could take hours to discover.\n Learning Outcome: I understood how even small schema changes can impact the\nwhole system and learned systematic debugging strategies in SQL Server.",
        "start_idx": 19745,
        "end_idx": 20414,
        "level": 2,
        "parent_id": "activity_analysis_1"
      },
      {
        "section_id": "activity_analysis_5",
        "section_name": "4. User Settings Integration",
        "content": "4. User Settings Integration\nAnother key task was implementing user-defined parameters (delimiter type, digit\ncount, sample size, and error thresholds). These directly affected how users interacted with\nthe system.\n11\n\n Technical Challenge: Ensuring smooth synchronization between frontend inputs and\nbackend validation.\n Reflection: I enjoyed this task the most because I could immediately see its impact\non usability. It reminded me that good engineering is not only about efficiency, but\nalso about creating a positive user experience.\n Learning Outcome: I learned how configurable systems are designed and why\nusability is a critical engineering principle.",
        "start_idx": 20416,
        "end_idx": 21245,
        "level": 2,
        "parent_id": "activity_analysis_1"
      },
      {
        "section_id": "activity_analysis_6",
        "section_name": "5. Master Product and Indicator Usage Check",
        "content": "5. Master Product and Indicator Usage Check\nI developed an endpoint to verify if indicators were already linked to a Master\nProduct, preventing accidental deletion of active indicators.\n Technical Challenge: Writing optimized queries that fetched relational data quickly\nwithout affecting system performance.\n Reflection: At first, I underestimated how much this small feature could improve\nsystem reliability. When the frontend team confirmed that it reduced user errors, I\nrealized its importance.\n Learning Outcome: I gained experience in designing defensive APIs and ensuring\nrelational integrity in enterprise systems.",
        "start_idx": 21247,
        "end_idx": 21994,
        "level": 2,
        "parent_id": "activity_analysis_1"
      },
      {
        "section_id": "activity_analysis_7",
        "section_name": "6. Debugging and Error Handling",
        "content": "6. Debugging and Error Handling\nThroughout the internship, I encountered and fixed many errors such as\nNullReferenceException, bulk insert MAXERRORS, and schema mismatches.\n Technical Challenge: Debugging often consumed entire days, especially when the\ncause was hidden in another part of the system.\n Reflection: At times it was frustrating, but solving a persistent error gave me a\nstrong sense of accomplishment. I also realized that debugging is one of the most\nvaluable skills in real projects.\n Learning Outcome: I developed systematic debugging techniques, learned how to\ntrace errors using Swagger and SSMS, and improved my resilience when facing\nunexpected problems.",
        "start_idx": 21996,
        "end_idx": 22824,
        "level": 2,
        "parent_id": "activity_analysis_1"
      },
      {
        "section_id": "activity_analysis_8",
        "section_name": "Reflection",
        "content": "Reflection\nEach task I worked on during the internship gave me a different perspective. The\ntechnical challenges (from merging endpoints to debugging migrations) taught me how\ntheoretical knowledge from university is applied in real projects. I realized that even small\nchanges, like user settings, can greatly improve usability, while larger tasks, like enumeration\nfunctions, require careful design to ensure efficiency.\nOn a personal level, I learned the value of patience and persistence. Debugging was\noften frustrating, but solving issues gave me confidence and showed me the importance of\nresilience. I also saw how teamwork and senior reviews (Alperen or Hüseyin abi checking\ncode before merging) build accountability and quality.\nOverall, the internship helped me bridge academic knowledge with industry\npractice, develop a stronger coding discipline, and understand that good engineering\nbalances technical accuracy with user trust.",
        "start_idx": 22826,
        "end_idx": 23795,
        "level": 2,
        "parent_id": "activity_analysis_1"
      },
      {
        "section_id": "activity_analysis_1",
        "section_name": "Activity Analysis",
        "content": "changes, like user settings, can greatly improve usability, while larger tasks, like enumeration\nfunctions, require careful design to ensure efficiency.\nOn a personal level, I learned the value of patience and persistence. Debugging was\noften frustrating, but solving issues gave me confidence and showed me the importance of\nresilience. I also saw how teamwork and senior reviews (Alperen or Hüseyin abi checking\ncode before merging) build accountability and quality.\nOverall, the internship helped me bridge academic knowledge with industry\npractice, develop a stronger coding discipline, and understand that good engineering\nbalances technical accuracy with user trust.\nActivity Analysis\nDescription of the Activity\nOne of the most critical engineering activities I carried out during my internship was\nthe development of an endpoint in the Indicator Controller that verifies whether an\n12\n\nindicator is already assigned to a Master Product. Before this feature, indicators could be\ndeleted freely, even if they were still in use. This caused serious problems, such as formulas\nbreaking and relational data becoming inconsistent.\nMy task was to implement a solution that prevented such issues. The endpoint had to:\n1. Return the names of the Master Products if the indicator was in use.\n2. Return null if the indicator was not used in any Master Product.\n3. Block deletion if the indicator was actively linked, while providing a user-friendly\nwarning message on the frontend.\nThis required coordination between the controller, service, and repository layers of\nthe ASP.NET Core application. I wrote the business logic in the service layer and created\noptimized queries to fetch the necessary relational data from SQL Server.\nPerformance Indicators and Metrics\nThe performance of this new endpoint was evaluated based on:\nData Integrity: Formulas and linked records were now preserved, since indicators could not\nbe deleted if still in use.\nSystem Reliability: Database errors caused by broken foreign keys were eliminated.\nUsability: The frontend team was able to integrate clear warnings, preventing users from\naccidentally deleting critical indicators.\nProblematic Issues in the Current Situation\nWhile the feature solved an important problem, it came with its own challenges:\nRelational Complexity: Finding the connection path between indicators and Master\nProducts was not straightforward. It required analyzing interface services and identifying\ncommon structures used across the system.\nQuery Design: Writing SQL queries that could handle multiple relational links without\nslowing down the system was difficult.\nIntegration: Returning simple, user-friendly error messages (instead of technical database\nerrors) required close collaboration with the frontend team.\nReflection and Learning Outcomes\nFor me, the most difficult part of this task was discovering the linkage path between\nindicators and Master Products. Navigating the shared structures in the service interfaces\ntook significant effort, and I realized how important system-level understanding is in\nbackend engineering.\nDespite the difficulties, this activity was also one of the most rewarding. It showed\nme how a relatively small feature could dramatically increase system reliability and user\ntrust. I learned how to design APIs that act as safeguards, how to improve communication\nbetween backend and frontend, and most importantly, how to ensure that relational\nintegrity is preserved in enterprise systems.\n13\n\nProject (only for XX300)\nDescription of the Activity\nDuring my internship, I was responsible for implementing User Settings parameters\nthat directly affected how data was processed and validated in the system. These included:\n Digit Count: how many digits are shown after the decimal point.\n Delimiter Type: how uploaded files (CSV/Excel) are parsed.\n Sample Size: how many rows are displayed in “Sample Data.”\n Max Error Threshold: the maximum allowed number of row-level errors in bulk data\ninsert operations.\nAt first, I thought this task would be simple and quick to finish. However,\nunderstanding the existing backend structure and replacing hard-coded logic with a dynamic\nsystem turned out to be much more complex than I expected. What I believed would take\nhalf a day initially stretched into three full days of work. Later, with more experience, I\nrealized I could complete similar tasks in less than an hour. This difference showed me how\nmuch I had grown in problem-solving efficiency during the internship.\nOn the frontend side, most of the interface was already prepared. My responsibility\nwas to make the backend flexible so that it could accept and validate dynamic user\nconfigurations rather than fixed parameters. This required updates in the controller,\nimprovements in the service layer, and additional validation logic in SQL queries.\nPerformance Indicators and Metrics\nThe success of this feature was measured by several factors:\n Accuracy of Data Parsing: With delimiter settings, CSV/Excel imports became\nconsistent and prevented column misalignment.\n System Usability: Users could preview exactly the number of rows they wanted with\nthe sample size setting.\n Error Handling Robustness: The Max Error Threshold allowed imports to fail\ngracefully instead of crashing completely.\n User Satisfaction: Since the frontend team did not need to hard-code configurations\nanymore, integration was smoother and more flexible.\nI personally observed performance overhead when handling large datasets during\nexport operations—errors appeared more slowly when the files were very large. This\nshowed that although the feature worked correctly, optimization was still necessary for\nscalability.\nProblematic Issues in the Current Situation\nDespite improvements, some issues remained:\nPerformance Overhead: Very large files slowed down preview and error detection.\nUser Misconfiguration: Some users selected unrealistic settings (e.g., max error = 0), which\nmade the system overly strict.\nScalability: Multiple concurrent users with custom configurations increased server load.\nProblem Definition\nThe legitimate Computer Engineering problem identified was:\nHow to design a user-specific data validation system that maximizes flexibility without\ndegrading performance or reliability?\nProposed Solution and Analysis\nTo address this, I suggested improvements such as:\nImproved Defaults: System-recommended default values (e.g., max error = 100) to avoid\nunrealistic user settings.\n14\n\nCaching Mechanisms: Caching common preview sizes to prevent repeated heavy queries.\nAsynchronous Processing: Handling large previews in background tasks to keep the UI\nresponsive.\nValidation Layer: Middleware checks to block invalid user settings before execution.\nWhile I solved the main implementation independently, my mentor Alperen\nprovided hints when I was stuck. This helped me learn without relying too much on others,\nand finishing the work myself was very satisfying.\nLiterature Survey and Alternative Approaches\nAcademic research in data quality management and ETL (Extract–Transform–Load) systems\noffers several alternative approaches:\n Adaptive Thresholding (Kandel et al., 2011): dynamically adjust error tolerance\nbased on dataset size.\n User-Centric Defaults (Nargesian et al., 2019): recommend default values derived\nfrom prior user behavior.\n Incremental Data Loading (Abadi et al., 2016): load datasets in smaller chunks to\nminimize the effect of errors.\nIncorporating such methods could further optimize Lumnion’s data validation pipeline and\nenhance both performance and user experience.\nConclusion\nThis project showed me how backend engineering and user experience are directly\nconnected. At first, I underestimated the complexity of the task, but working through it\ntaught me how small configuration features can have large impacts on usability and\nperformance. More importantly, I learned how to approach a problem step by step:\nanalyzing requirements, implementing changes, validating with real data, and considering\nimprovements through academic research.\nBy completing this task, I gained not only technical knowledge in ASP.NET Core, SQL\nServer, and API design but also practical lessons about efficiency, usability, and independent\nproblem-solving.\n15",
        "start_idx": 23734,
        "end_idx": 29645,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "activity_analysis_9",
        "section_name": "Activity Analysis",
        "content": "Activity Analysis\nDescription of the Activity\nOne of the most critical engineering activities I carried out during my internship was\nthe development of an endpoint in the Indicator Controller that verifies whether an\n12",
        "start_idx": 23797,
        "end_idx": 24113,
        "level": 2,
        "parent_id": "activity_analysis_1"
      },
      {
        "section_id": "conclusion_1",
        "section_name": "3. Conclusions (maximum one page)",
        "content": "3. Conclusions (maximum one page)\nDuring my internship at Lumnion Bilişim Teknolojileri, I engaged in a wide range of\nsoftware engineering activities, including backend development, database management,\nand system validation. My main contributions were:\n Developing and refactoring backend endpoints such as the Save Rule endpoint.\n Designing enumeration functions in SQL for dynamic actuarial data handling.\n Managing Entity Framework Core migrations and schema updates.\n Implementing user-specific settings (delimiter, digit count, sample size, error\nthresholds).\n Creating validation endpoints to ensure indicator–master product integrity.\n Debugging and solving runtime issues such as null references and bulk insert errors.\nThrough these activities, I learned how my theoretical knowledge in database\nsystems, software architecture, and algorithms translates into enterprise-level applications. I\nalso developed practical skills in ASP.NET Core, SQL Server, and Entity Framework Core,\nwhile gaining professional habits such as systematic debugging, clean code writing, and\neffective use of Git branching workflows.\nThe working environment I experienced was one of the most valuable parts of the\ninternship. Meetings were always held with strong discipline and started on time, yet there\nwas never unnecessary pressure. If someone could not attend, no one reacted negatively;\ninstead, there was an atmosphere of understanding and support. Team members helped\neach other frequently, and even if someone could not complete a task during the day, they\nmade sure to contribute later. This balance of discipline and flexibility created a highly\ncollaborative and motivating workplace culture.\nFrom a sectoral perspective, the InsurTech industry continues to grow rapidly, with\nLumnion holding a strong position domestically. However, competing in international\nmarkets presents challenges, particularly against well-established players like Prophet. The\nmajor technical challenges of the sector include handling massive datasets, integrating\nmachine learning into production systems, and ensuring compliance with complex financial\nregulations.\nLooking into the next five to ten years, I believe the industry will be significantly\nshaped by cryptology and cybersecurity. As insurance products increasingly rely on large\ndatasets and cloud-based infrastructures, protecting data integrity and privacy will be as\nimportant as developing accurate models. Innovations in cryptology will enhance secure\ntransactions, while advancements in cybersecurity will protect sensitive financial and\ncustomer data against evolving threats. These developments will complement ongoing\ntransformations driven by AI, big data, and automation, making InsurTech both more\npowerful and more responsible.\nIn conclusion, this internship not only strengthened my technical abilities but also gave\nme a clear view of the professional responsibilities and future challenges in the InsurTech\n16\n\nsector. I finished the program with stronger coding skills, a deeper appreciation of\nteamwork, and a sharper vision of how technology and ethics intersect in real-world\nengineering.",
        "start_idx": 29645,
        "end_idx": 31648,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "impact_1",
        "section_name": "a. Impact (minimum one page)",
        "content": "a. Impact (minimum one page)\nDuring my internship at Lumnion Bilişim Teknolojileri, I realized that even the technical\ntasks I contributed to—such as developing backend endpoints, optimizing SQL queries, or\nimplementing user settings—can have a broader global, economic, environmental, and\nsocietal impact. While at first these seemed like purely technical details, I gradually saw how\nthey connect to larger issues such as international compliance, financial efficiency, and\ncustomer trust.\nGlobal Impact\nInsurance is by nature a global industry, and the software solutions developed at\nLumnion are designed not only for domestic use but also for international clients. Although I\npersonally did not attend international client meetings, I observed how senior staff such as\nthe CEO and chief analysts frequently engaged with foreign partners.\nEconomic Impact\nThe economic effect of software engineering in the InsurTech sector is significant. By\nimproving reliability and preventing errors, we help companies reduce operational costs. For\nexample, the Max Error Threshold feature I worked on prevented entire bulk data uploads\nfrom crashing, which saves both time and money. In addition to error reduction, there is also\na strong element of labor efficiency. Automating repetitive tasks reduces the need for\nmanual corrections and allows engineers and actuaries to focus on higher-value analytical\nwork. In the long run, this improves company profitability and ensures customers receive\nfairer and more transparent premium calculations.\nEnvironmental Impact\nAlthough software engineering does not directly produce physical waste, its\nenvironmental footprint comes from the computational power used by servers and cloud\nservices. By writing optimized queries and designing more efficient data validation logic, the\nsystem consumes fewer resources on cloud platforms such as Azure and AWS. This indirectly\ncontributes to lower energy consumption, which is critical given the increasing energy\ndemands of large-scale data processing. While I did not work directly on cloud resource\nmanagement, my tasks still played a role in minimizing unnecessary processing, which is a\nsubtle but meaningful contribution to sustainability.\nSocietal Impact\nPerhaps the most visible impact is at the societal level. Insurance companies play a\ncrucial role in protecting individuals and businesses from financial risks. If the software\nbehind these companies is unreliable or prone to errors, the trust of customers can be\nseverely damaged. By implementing safeguards such as indicator, master product validation\nand user-specific settings, I contributed to ensuring that pricing models remain consistent\nand transparent. This benefits both sides:\n17",
        "start_idx": 31648,
        "end_idx": 33635,
        "level": 2,
        "parent_id": "conclusion_1"
      },
      {
        "section_id": "conclusion_2",
        "section_name": "Conclusion",
        "content": "In short, my internship taught me that engineering solutions are never isolated. A single\nbackend improvement can have ripple effects: globally, it supports compliance and\ncompetitiveness; economically, it saves costs and labor; environmentally, it reduces energy\nusage; and socially, it strengthens trust and fairness in financial systems. As an engineering\nstudent, this realization was important because it showed me how technical work\ncontributes to broader global, economic, environmental, and societal outcomes, and that\neven small changes at the code level can create a significant impact.",
        "start_idx": 37360,
        "end_idx": 37841,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "team_work_1",
        "section_name": "b. Team Work (maximum one page)",
        "content": "In the CashFlow team, I worked closely with both backend and frontend developers, each\nwith clearly defined responsibilities.\nOn the backend side, our team included:\n Alperen (Senior Backend Engineer): He was not only responsible for the core\narchitecture but also took care of company-level setup tasks like deployments and\nenvironment configurations. Nothing could be pushed to the backend without his\nreview and approval, which ensured code quality and stability.\n Arca (Junior Backend Engineer): He mainly focused on running processes and\noperational tasks, ensuring that the system was functioning correctly during\ndevelopment.\n Me (Intern Backend Engineer): At first, I started with smaller, slower tasks as I was\nstill learning. Over time, I moved on to handling general backend work, such as\ndeveloping endpoints, debugging issues, and working with migrations. This helped\nme feel like a true contributor to the backend team.\nOn the frontend side, the team included:\n Hüseyin (Senior Frontend Engineer): He had the final say in frontend development.\nNothing could be pushed to production without his approval, which maintained a\nconsistent and reliable UI/UX.\n Berke (Junior Frontend Engineer): He supported the development process by\nimplementing features and assisting with frontend–backend integration.\n Sena (Intern Frontend Engineer): She contributed by learning through hands-on\ntasks and supporting the junior and senior developers with smaller assignments.",
        "start_idx": 37842,
        "end_idx": 39261,
        "level": 2,
        "parent_id": "conclusion_1"
      },
      {
        "section_id": "self_directed_learning_1",
        "section_name": "c. Self-directed Learning (minimum one page)",
        "content": "One of the most important lessons I gained from this internship was the value of self-\ndirected and lifelong learning. From the very first week, I understood that the technologies\nused in the CashFlow project—such as ASP.NET Core, Entity Framework, SQL Server, Docker,\nand GitHub workflows—were beyond the level I had fully studied at university. In order to\ncontribute effectively, I realized that I had to take initiative and build my knowledge\nindependently.\nAt the beginning, I followed the recommendations of the backend and frontend\ndevelopers and enrolled in Udemy courses on ASP.NET Core and SQL/Entity Framework. These\ncourses helped me strengthen my foundation, but I quickly noticed that the material did not\nalways match the exact problems I was facing in the project. For example, while the course\nexplained the basics of migrations and entity relationships, the real challenge in my tasks was\ndebugging unexpected runtime errors and adapting schema changes to a live project. At first\nthis was discouraging, but later I realized that the value of courses lies in giving a conceptual\nmap, while the real learning comes from hands-on experimentation and problem-solving in\nreal projects.\nBy the second week, during sprint planning, I was assigned a small task, but my personal\ngoal was to finish another course in parallel. Even though the tasks seemed simple, I soon\nlearned that progress required not just following instructions, but also curiosity and initiative.\nFor example, when implementing backend endpoints, I often stopped and researched not only\nhow to fix an error, but also why it was happening. This habit of “digging deeper” became one\nof my strongest learning strategies.\nI also benefited a lot from mentorship and observation. I frequently consulted Alperen,\nthe senior backend engineer, about deployment processes. He introduced me both to\nLumnion’s internal setup (using Docker, Git branching, and application installation) and to\nhow deployments were handled for external companies via virtual machines. These insights\nshowed me how large-scale software systems are managed in real life, going far beyond what\nI had learned in class. Although Alperen sometimes gave me hints, he encouraged me to solve\nproblems independently. Completing tasks on my own, after struggling for days, gave me\nconfidence and reinforced my learning far more than simply being told the answer.\nAnother area I explored with Alperen was ethical hacking. While this was more of a side\ncuriosity, we experimented with small exercises and even discussed potential issues related\nto CashFlow tokens. This made me realize how important security is in financial software, and\nwhy engineers must always think about vulnerabilities as well as features. Even though these\nexplorations were not part of my official assignments, they broadened my perspective and\nmotivated me to study security more seriously in the future.",
        "start_idx": 39262,
        "end_idx": 41755,
        "level": 2,
        "parent_id": "conclusion_1"
      },
      {
        "section_id": "references_1",
        "section_name": "References",
        "content": "1- Microsoft, 2025. ASP.NET Core Documentation.\nhttps://learn.microsoft.com/en-us/aspnet/core/\n2- Microsoft, 2025. Entity Framework Core Documentation.\nhttps://learn.microsoft.com/en-us/ef/core/\n3- Microsoft, 2025. SQL Server Technical Documentation.\nhttps://learn.microsoft.com/en-us/sql/\n4- International Financial Reporting Standards (IFRS), 2025. IFRS 17 Insurance Contracts.\nhttps://www.ifrs.org/issued-standards/list-of-standards/ifrs-17-insurance-contracts/\n5- Solvency II Directive, 2025. Directive 2009/138/EC of the European Parliament and of the\nCouncil.\nhttps://ec.europa.eu/info/business-economy-euro/banking-and-finance/insurance-and-\npensions/risk-management/solvency-2_en\n6- IEEE/ACM, 2025. Software Engineering Code of Ethics.\nhttps://ethics.acm.org/code-of-ethics/software-engineering-code/\n7- Kandel, S., Paepcke, A., Hellerstein, J. and Heer, J., 2011. Wrangler: Interactive visual\nspecification of data transformation scripts. Proceedings of the SIGCHI Conference on Human\nFactors in Computing Systems (CHI '11), pp.3363–3372.\n8- Nargesian, F., Zhu, E., Miller, R.J., Pu, K.Q. and Zhang, H., 2019. Table Union Search on\nOpen Data. Proceedings of the VLDB Endowment, 11(7), pp.813–825.\n9- Abadi, D.J., Ahmad, Y., Balazinska, M., Cetintemel, U., Cherniack, M., Hwang, J.H., Lindner,\nW., Maskey, A., Rasin, A., Ryvkina, E., Tatbul, N., Xing, Y. and Zdonik, S., 2016. The Design of\nthe Borealis Stream Processing Engine. Foundations and Trends in Databases, 4(1), pp.1–\n123.\n10- Lumnion, 2025. Lumnion Official Website.\nhttps://www.lumnion.com/",
        "start_idx": 41756,
        "end_idx": 43361,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_1",
        "section_name": "Appendix 1: Daily Activity Tables",
        "content": "My first day started with an introduction to the company and the CashFlow project. I spent\nmost of the day setting up my development environment and making sure all required tools\nlike Visual Studio, SQL Server Management Studio, and Git were running properly. I also\njoined my first daily meeting at 9:00, where I observed how tasks were shared among the\nteam. In the afternoon, I began a Udemy course recommended by my teammates to\nstrengthen my backend knowledge.\nDate Supervisor’s Name Signature\n07.07.2025 Eray Alpan\nOn the second day, I worked from home and continued with the Udemy course. I also spent\ntime observing how backend developers like Alperen and Arca handled migrations and\ndatabase operations. Even though I wasn’t coding yet, I learned a lot by watching how they\ndebugged problems in the project. This gave me a better picture of the workflow and the\nchallenges I would face later.\nDate Supervisor’s Name Signature\n08.07.2025 Eray Alpan",
        "start_idx": 43362,
        "end_idx": 44659,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_2",
        "section_name": "Date Supervisor’s Name Signature\n09.07.2025 Eray Alpan",
        "content": "I attended the daily stand-up in the morning and listened to updates from the frontend and\nbackend sides. I continued with the Udemy course, focusing on Entity Framework basics.\nLater, there was an investor meeting where I joined as a listener. Even though I didn’t\ncontribute, it was interesting to see how technical progress is reported to stakeholders.\nDate Supervisor’s Name Signature\n09.07.2025 Eray Alpan",
        "start_idx": 44660,
        "end_idx": 45260,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_3",
        "section_name": "Date Supervisor’s Name Signature\n10.07.2025\nEray Alpan",
        "content": "This was my second day at the office. I joined the product meeting about the company’s\nother platform. Most of the day I continued my course and asked Alperen a few questions\nabout system setup and deployments. I also watched closely how the frontend team worked\nwith API responses, which gave me ideas about how backend and frontend interact.\nDate Supervisor’s Name Signature\n10.07.2025\nEray Alpan",
        "start_idx": 45261,
        "end_idx": 45900,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_4",
        "section_name": "Date Supervisor’s Name Signature\n11.07.2025 Eray Alpan",
        "content": "I spent the day at home, mainly focused on finishing sections of my Udemy course. I also\nshadowed some of Arca’s work related to running services. This gave me more\nunderstanding of how backend jobs are triggered and monitored. It was a quiet but useful\nday for learning.\nDate Supervisor’s Name Signature\n11.07.2025 Eray Alpan",
        "start_idx": 45901,
        "end_idx": 46489,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_5",
        "section_name": "Date Supervisor’s Name Signature\n14.07.2025 Eray Alpan",
        "content": "This week started with my first sprint planning meeting, where the next two weeks of tasks\nwere discussed. I still wasn’t assigned heavy work, but I was given a small task related to\nmigrations. The task was to review how new columns were being added and to check error\nmessages in SQL Server. Alongside this, I continued another Udemy course to strengthen my\nbackend fundamentals.\nDate Supervisor’s Name Signature\n14.07.2025 Eray Alpan",
        "start_idx": 46490,
        "end_idx": 47192,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_6",
        "section_name": "Date Supervisor’s Name Signature\n16.07.2025 Eray Alpan",
        "content": "I joined the daily in the morning, then spent most of the day finalizing the second Udemy\ncourse. I also did a small fix on nullable IDs with the guidance of Arca. It was the first time I\ntouched actual project code, even though it was something minor. This small success\nmotivated me a lot.\nDate Supervisor’s Name Signature\n16.07.2025 Eray Alpan",
        "start_idx": 47193,
        "end_idx": 47810,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_7",
        "section_name": "Date Supervisor’s Name Signature\n17.07.2025 Eray Alpan",
        "content": "On Thursday, I went to the office again. After the daily, I joined the product meeting. I also\nhandled another small backend task that involved checking for errors in database queries.\nEven though the task was not complex, it was interesting to see how careful validation\nprevents bigger errors later.\nDate Supervisor’s Name Signature\n17.07.2025 Eray Alpan",
        "start_idx": 47811,
        "end_idx": 48440,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_8",
        "section_name": "Date Supervisor’s Name Signature\n18.07.2025\nEray Alpan",
        "content": "From home, I reviewed the design of the Save Rule endpoint. My job was not to code it yet,\nbut to understand how the existing Create and Update endpoints worked. I took notes about\ntheir similarities and differences. This preparation was important because from the next\nweek onwards, I would start working on larger backend tasks\nDate Supervisor’s Name Signature\n18.07.2025\nEray Alpan",
        "start_idx": 48441,
        "end_idx": 49101,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_9",
        "section_name": "Date Supervisor’s Name Signature\n21.07.2025 Eray Alpan",
        "content": "The week started with a sprint planning session. In this sprint, my main focus was the Save\nRule endpoint. At the office, Alperen explained how Create and Update were currently\nseparated and why merging them into Save would make the system cleaner. I studied the\ncontroller and service layers, identifying repeated logic that could be consolidated. This gave\nme a much clearer roadmap for the coming days.\nDate Supervisor’s Name Signature\n21.07.2025 Eray Alpan",
        "start_idx": 49102,
        "end_idx": 49800,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_10",
        "section_name": "Date Supervisor’s Name Signature\n22.07.2025 Eray Alpan",
        "content": "I started implementing the Save Rule endpoint at home. My work began with the controller\nlayer, adding the new route and defining request parameters. It was challenging because I\nhad to ensure the endpoint could handle both new and existing IDs. I also reviewed Entity\nFramework’s transaction handling to prevent data corruption if something went wrong.\nDate Supervisor’s Name Signature\n22.07.2025 Eray Alpan",
        "start_idx": 49801,
        "end_idx": 50504,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_11",
        "section_name": "Date Supervisor’s Name Signature\n23.07.2025 Eray Alpan",
        "content": "The coding continued. I worked mainly on the service layer, where I had to separate logic for\ncreate vs. update without duplicating code. It took me a while to debug null reference\nissues, but with Arca’s help I managed to resolve them. In the afternoon, there was an\ninvestor meeting. Although I mostly listened, it helped me understand how backend stability\ndirectly affects customer confidence.\nDate Supervisor’s Name Signature\n23.07.2025 Eray Alpan",
        "start_idx": 50505,
        "end_idx": 51211,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "activity_analysis_2",
        "section_name": "Activity Analysis / Project",
        "content": "I started implementing the Save Rule endpoint at home. My work began with the controller\nlayer, adding the new route and defining request parameters. It was challenging because I\nhad to ensure the endpoint could handle both new and existing IDs. I also reviewed Entity\nFramework’s transaction handling to prevent data corruption if something went wrong.\nDate Supervisor’s Name Signature\n22.07.2025 Eray Alpan\nThe coding continued. I worked mainly on the service layer, where I had to separate logic for\ncreate vs. update without duplicating code. It took me a while to debug null reference\nissues, but with Arca’s help I managed to resolve them. In the afternoon, there was an\ninvestor meeting. Although I mostly listened, it helped me understand how backend stability\ndirectly affects customer confidence.\nDate Supervisor’s Name Signature\n23.07.2025 Eray Alpan\n27\n\nAt the office, I tested the Save Rule endpoint using Swagger and Postman. The feature\nworked in most cases, but I found a few bugs when handling missing IDs. Alperen suggested\nadding clearer validation messages so the frontend team could easily display them. Later, I\njoined the weekly product meeting about the platform product. It was useful to see how\ndifferent teams coordinate.\nDate Supervisor’s Name Signature\n24.07.2025 Eray Alpan\nI finalized the Save Rule endpoint and documented my changes. This included writing down\nthe request/response formats and validation rules. I also cleaned up some redundant code\nfrom the old endpoints. This task was the first real feature I completed almost\nindependently, which gave me a big confidence boost.\nDate Supervisor’s Name Signature\n25.07.2025 Eray Alpan\n28\n\nA new sprint started, and my task was to begin work on enumeration functions in SQL. I\nstarted with INT_TO_ENUM and ENUM_SIZE. Alperen explained how actuarial models often\ndepend on these mappings, so the functions had to be reliable. I created draft SQL functions\nand tested them with simple cases in SSMS.\nDate Supervisor’s Name Signature\n28.07.2025 Eray Alpan\nI refined INT_TO_ENUM by making sure it could handle invalid inputs gracefully (returning\nnull). Then I worked on ENUM_SIZE, which required counting the number of key–value pairs\nin a table. It looked simple at first, but I had to ensure it worked across different\nenumeration tables dynamically. Debugging this taught me a lot about SQL function design.\nDate Supervisor’s Name Signature\n29.07.2025 Eray Alpan\n29\n\nI started exploring the more complex READ_FROM_TABLE function. This required retrieving\na value by matching multiple row headers. The logic was tricky because the number of\nheaders could vary. I spent most of the day analyzing how to dynamically construct SQL\nqueries to handle different cases.\nDate Supervisor’s Name Signature\n30.07.2025 Eray Alpan\nI continued implementing READ_FROM_TABLE. At the office, I asked Alperen for help with\nhandling text vs. numeric types. Together, we tested queries to ensure correct results when\nrow headers were strings. Later, in the product meeting, I realized how important these\nfunctions were because they directly supported actuarial formulas that customers rely on.\nDate Supervisor’s Name Signature\n31.07.2025 Eray Alpan\n30\n\nI completed the first working version of READ_FROM_TABLE and tested it with sample\ntables. Some cases worked perfectly, but others failed when row headers were missing. I\ndocumented the problems and planned fixes for the next sprint. Even though it wasn’t\nperfect, I felt satisfied with making real progress on such a complex function.\nDate Supervisor’s Name Signature\n01.08.2025 Eray Alpan\nA new sprint started, and my focus shifted to User Settings integration. I began with the\ndelimiter and digit count parameters. At the office, I reviewed how these settings were\nstored in the database and how they should be applied dynamically to user operations. It\nwas interesting to see how small configuration changes could affect the whole data input\npipeline.\nDate Supervisor’s Name Signature\n04.08.2025 Eray Alpan\n31\n\nI continued with User Settings, this time working on sample size. The challenge was to\nensure the system could display a user-defined number of rows in the preview without\ncausing performance issues. I tested with different sample sizes and realized that very large\nvalues slowed down the system, so we added sensible limits.\nDate Supervisor’s Name Signature\n05.08.2025 Eray Alpan\nMy task for the day was to connect the max error threshold parameter to bulk insert\noperations. This meant that if the user set a threshold of, for example, 50, the import would\nstop only after 50 errors instead of failing immediately. I modified the controller to pass this\nparameter to the service layer. It was a challenging but very practical task since it improved\nusability for real customers.\nDate Supervisor’s Name Signature\n06.08.2025 Eray Alpan\n32\n\nAt the office, I tested all of the User Settings together: delimiter, digit count, sample size,\nand max error threshold. There were some issues with how the frontend displayed decimals,\nso I worked with Hüseyin to make sure the backend responses were aligned with the UI. In\nthe afternoon, we had the weekly product meeting, where I presented the progress on\nthese settings.\nDate Supervisor’s Name Signature\n07.08.2025 Eray Alpan\nI spent most of the day debugging small issues related to User Settings. For example, when\nthe delimiter was not specified, the system sometimes defaulted incorrectly. Fixing these\nedge cases helped me understand the importance of validation and default values. By the\nend of the week, the User Settings feature was functioning well.\nDate Supervisor’s Name Signature\n08.08.2025 Eray Alpan\n33\n\nA new sprint began, and I moved on to the Master Product–Indicator check endpoint. The\ngoal was to prevent indicators from being deleted if they were still assigned to a Master\nProduct. At the office, I worked with Alperen to design the controller route and service logic.\nIt was exciting because this task required thinking about data integrity and relational\nconstraints.\nDate Supervisor’s Name Signature\n11.08.2025 Eray Alpan\nI continued coding the endpoint at home. The main challenge was writing a query that could\nfetch all Master Product names linked to a given indicator. I also made sure the endpoint\nwould return null if no link existed. It was tricky to handle these conditions correctly, but I\nlearned a lot about working with relationships in Entity Framework.\nDate Supervisor’s Name Signature\n13.08.2025 Eray Alpan\n34\n\nI tested the new endpoint thoroughly. When an indicator was linked, the endpoint\nsuccessfully returned the Master Product names. When not linked, it returned null as\nexpected. During the investor meeting, I realized how important this feature was:\npreventing broken references builds customer trust in the system. I documented all tests\nand bug fixes.\nDate Supervisor’s Name Signature\n12.08.2025 Eray Alpan\nThis was my last full working day at the office. I finalized the Master Product–Indicator\nendpoint and presented it in the product meeting. I also had a closing discussion with the\nteam about what I learned during my internship. Looking back, I was proud of my progress—\nfrom starting slowly with courses and small fixes to completing full backend features.\nDate Supervisor’s Name Signature\n14.08.2025 Eray Alpan\n35\n\nAlthough this was officially my last internship day, I mostly focused on wrapping up\ndocumentation and preparing my internship report. I also joined the daily meeting one last\ntime and thanked the team for their support. It was a nice closing to an internship where I\nlearned not just technical skills but also how to work effectively in a real development team.\nDate Supervisor’s Name Signature\n15.08.2025 Eray Alpan",
        "start_idx": 50611,
        "end_idx": 55022,
        "level": 1,
        "parent_id": null
      },
      {
        "section_id": "internship_documents_1",
        "section_name": "Internship Documents",
        "content": "36\n\nAppendix 2:\nFigure 1. Service of ReloaProductCounts function which I coded, PART I.\n37\n\nFigure 2 Service of ReloaProductCounts function which I coded, PART II.\nFigure 3. EndPoint of ReloaProductCounts function.\nFigure 4. Interface Service of FormulaVariableService function which I coded fully.\n38\n\nFigure 5. Controller of FormulaVariableService function which I coded fully.\n39\n\nFigure 6. Service of FormulaVariableService function which I coded fully PART I.\n40\n\nFigure 7. Service of FormulaVariableService function which I coded fully PART II.\n41\n\nFigure 8. Service of FormulaVariableService function which I coded fully PART III.\n42\n\nFigure 9. Service of FormulaVariableService function which I coded fully PART IV.\n43\n\nFigure 10. Service of FormulaVariableService function which I coded fully PART V.\n44\n\nFigure 11. Service of FormulaVariableService function which I coded fully PART VI.\n45\n\nFigure 12. Service of FormulaVariableService function which I coded fully PART VII.\nFigure 13. Service of FormulaVariableService function which I coded fully PART VIII.\n46\n\nInternship Documents\nCHECKLIST\nDepartment Name Engineering Practice\nMEF University\nFor the completeness of your internship report submission, you are held responsible to\ncheck the submission of the following items. The marked final checklist should be\nincluded to your submitted internship report as the last page. Student Evaluation\nSurvey has to be submitted only through SIS.\n Internship Application and Acceptance Form signed/stamped? (Critical)\n Internship Report (Critical)\n Internship Evaluation Form enclosed/sealed (Critical)\n(needs to be filled with pen, or via the link sent directly to the\ncompany. Either way, form should be signed and enclosed)\n Daily activity pages signed? (Critical)\n Additional material (such as source codes) attached to the submitted report\n(Non-Critical)\n Internship Report bound and plastic-covered? (Critical)\n Internship Report and all accompanying material submitted in an envelope.\n Hereby, I accept liability for the accuracy and integrity of the submitted\ncontents.\nStudent Name:\nSignature:\nDate:\n47",
        "start_idx": 55022,
        "end_idx": 56102,
        "level": 1,
        "parent_id": null
      }
    ]
  },
  "source_metadata": {
    "total_length": 60507,
    "extraction_timestamp": "2025-11-13T20:51:22.840440",
    "chunked": true,
    "chunk_count": 5
  }
}