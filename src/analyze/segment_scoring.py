"""
Segment Scoring Module
Cover segmenti iÃ§in LLM tabanlÄ± puanlama sistemi.
Rubrik kriterlerine gÃ¶re: baÅŸlÄ±k doÄŸruluÄŸu, biÃ§im, bilgi tamlÄ±ÄŸÄ±, tarih/isim varlÄ±ÄŸÄ±.
"""

import os
import json
import csv
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import google.generativeai as genai

MODEL_NAME = "gemini-2.0-flash"


def load_prompt() -> str:
    """Cover scoring iÃ§in LLM prompt ÅŸablonunu yÃ¼kle"""
    # Proje root'unu bul (src/analyze'den 2 seviye yukarÄ±)
    project_root = Path(__file__).resolve().parents[2]
    prompt_path = project_root / "llm" / "prompts" / "cover_scoring.json.txt"
    
    if not prompt_path.exists():
        raise FileNotFoundError(f"Prompt dosyasÄ± bulunamadÄ±: {prompt_path}")
    
    return prompt_path.read_text(encoding="utf-8")


def find_first_segment(segmentation_json: Dict) -> Optional[Dict]:
    """
    Segmentasyon JSON'dan ilk segmenti bul.
    Ã–ncelik: section_id == 'cover_1', yoksa level == 1 olan ilk segment.
    
    Args:
        segmentation_json: Segmentasyon JSON dict'i
        
    Returns:
        Ä°lk segment dict'i veya None
    """
    sections = segmentation_json.get("segmentation", {}).get("sections", [])
    
    if not sections:
        return None
    
    # Ã–nce cover_1'i ara
    for section in sections:
        if section.get("section_id") == "cover_1":
            return section
    
    # Yoksa level == 1 olan ilk segmenti al
    for section in sections:
        if section.get("level") == 1:
            return section
    
    # HiÃ§biri yoksa ilk segmenti al
    return sections[0] if sections else None


def score_segment(segment: Dict, api_key: str = None) -> Dict:
    """
    Bir segmenti rubrik kriterlerine gÃ¶re puanla.
    
    Args:
        segment: Segment dict'i (section_id, section_name, content, vb.)
        api_key: Gemini API key (opsiyonel, env'den alÄ±nÄ±r)
        
    Returns:
        {
            "score": float,  # Toplam puan (0-10)
            "feedback": str,  # DetaylÄ± geri bildirim
            "criteria": {
                "title_accuracy": float,  # BaÅŸlÄ±k doÄŸruluÄŸu (0-10)
                "format": float,          # BiÃ§im (0-10)
                "completeness": float,    # Bilgi tamlÄ±ÄŸÄ± (0-10)
                "date_name_presence": float  # Tarih/isim varlÄ±ÄŸÄ± (0-10)
            }
        }
    """
    api_key = api_key or os.getenv("GEMINI_API_KEY", "")
    if not api_key:
        raise RuntimeError("GEMINI_API_KEY is not set")
    
    genai.configure(api_key=api_key)
    
    model = genai.GenerativeModel(
        MODEL_NAME,
        generation_config={
            "temperature": 0.3,  # Biraz yaratÄ±cÄ±lÄ±k iÃ§in
            "response_mime_type": "application/json"
        },
        safety_settings={}
    )
    
    # Prompt'u yÃ¼kle ve formatla
    prompt_template = load_prompt()
    prompt = prompt_template.format(
        SECTION_NAME=segment.get("section_name", ""),
        CONTENT=segment.get("content", "")
    )
    
    # LLM'den puanlama al
    max_retries = 3
    retry_delay = 5
    
    for attempt in range(max_retries):
        try:
            resp = model.generate_content(prompt)
            output_text = _extract_text(resp).strip()
            
            # JSON temizleme
            if "```json" in output_text:
                start = output_text.find("```json") + 7
                end = output_text.find("```", start)
                if end != -1:
                    output_text = output_text[start:end].strip()
            elif "```" in output_text:
                start = output_text.find("```") + 3
                end = output_text.find("```", start)
                if end != -1:
                    output_text = output_text[start:end].strip()
            
            # JSON parse
            result = json.loads(output_text)
            
            # Validasyon: gerekli alanlar var mÄ±?
            if "score" not in result:
                raise ValueError("LLM Ã§Ä±ktÄ±sÄ±nda 'score' alanÄ± bulunamadÄ±")
            if "criteria" not in result:
                raise ValueError("LLM Ã§Ä±ktÄ±sÄ±nda 'criteria' alanÄ± bulunamadÄ±")
            
            return result
            
        except json.JSONDecodeError as e:
            if attempt < max_retries - 1:
                import time
                time.sleep(retry_delay)
                continue
            raise RuntimeError(f"JSON parse hatasÄ±: {e}\nÃ‡Ä±ktÄ±: {output_text[:500]}")
        except Exception as e:
            error_str = str(e)
            if "429" in error_str or "Resource exhausted" in error_str:
                if attempt < max_retries - 1:
                    import time
                    wait_time = retry_delay * (attempt + 1)
                    print(f"âš ï¸  Rate limit hatasÄ±. {wait_time} saniye bekleniyor...")
                    time.sleep(wait_time)
                    continue
                else:
                    raise RuntimeError("API rate limit aÅŸÄ±ldÄ±. LÃ¼tfen birkaÃ§ dakika bekleyip tekrar deneyin.")
            raise
    
    raise RuntimeError("LLM'den geÃ§erli Ã§Ä±ktÄ± alÄ±namadÄ±.")


def _extract_text(resp) -> str:
    """Gemini yanÄ±tÄ±ndan metni gÃ¼venli biÃ§imde Ã§Ä±kar"""
    if not resp:
        return ""
    if getattr(resp, "text", None):
        return resp.text
    try:
        parts = []
        for c in getattr(resp, "candidates", []) or []:
            for part in getattr(c, "content", {}).parts or []:
                if getattr(part, "text", None):
                    parts.append(part.text)
        return "".join(parts)
    except Exception:
        return ""


def test_multiple_reports(segmentation_files: List[Path], output_csv: Path = None) -> List[Dict]:
    """
    Birden fazla segmentation JSON dosyasÄ±nÄ± test et ve sonuÃ§larÄ± CSV'ye kaydet.
    
    Args:
        segmentation_files: Test edilecek segmentation JSON dosya yollarÄ±
        output_csv: CSV Ã§Ä±ktÄ± dosyasÄ± yolu (opsiyonel)
        
    Returns:
        Test sonuÃ§larÄ± listesi
    """
    results = []
    
    for seg_file in segmentation_files:
        print(f"\nğŸ“„ Ä°ÅŸleniyor: {seg_file.name}")
        
        try:
            # JSON'u yÃ¼kle
            with open(seg_file, 'r', encoding='utf-8') as f:
                seg_data = json.load(f)
            
            # Ä°lk segmenti bul
            first_segment = find_first_segment(seg_data)
            if not first_segment:
                print(f"  âš ï¸  Ä°lk segment bulunamadÄ±, atlanÄ±yor.")
                continue
            
            print(f"  âœ… Segment bulundu: {first_segment.get('section_id', 'unknown')}")
            
            # Puanla
            score_result = score_segment(first_segment)
            
            # SonuÃ§larÄ± kaydet
            result = {
                "file_name": seg_file.name,
                "section_id": first_segment.get("section_id", ""),
                "section_name": (first_segment.get("section_name", "") or "")[:100],  # Ä°lk 100 karakter
                "total_score": score_result.get("score", 0.0),
                "title_accuracy": score_result.get("criteria", {}).get("title_accuracy", 0.0),
                "format": score_result.get("criteria", {}).get("format", 0.0),
                "completeness": score_result.get("criteria", {}).get("completeness", 0.0),
                "date_name_presence": score_result.get("criteria", {}).get("date_name_presence", 0.0),
                "feedback": score_result.get("feedback", "")[:500],  # Ä°lk 500 karakter
                "timestamp": datetime.now().isoformat()
            }
            
            results.append(result)
            
            print(f"  ğŸ“Š Toplam Puan: {result['total_score']:.2f}/10")
            print(f"     - BaÅŸlÄ±k DoÄŸruluÄŸu: {result['title_accuracy']:.2f}/10")
            print(f"     - BiÃ§im: {result['format']:.2f}/10")
            print(f"     - Bilgi TamlÄ±ÄŸÄ±: {result['completeness']:.2f}/10")
            print(f"     - Tarih/Ä°sim VarlÄ±ÄŸÄ±: {result['date_name_presence']:.2f}/10")
            
        except Exception as e:
            print(f"  âŒ Hata: {e}")
            results.append({
                "file_name": seg_file.name,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
    
    # CSV'ye kaydet
    if output_csv and results:
        output_csv.parent.mkdir(parents=True, exist_ok=True)
        
        # CSV baÅŸlÄ±klarÄ±
        fieldnames = [
            "file_name", "section_id", "section_name", "total_score",
            "title_accuracy", "format", "completeness", "date_name_presence",
            "feedback", "timestamp"
        ]
        
        # CSV'ye append (mevcut dosyayÄ± oku ve yeni sonuÃ§larÄ± ekle)
        file_exists = output_csv.exists()
        existing_results = []
        if file_exists:
            try:
                with open(output_csv, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    existing_results = list(reader)
            except Exception:
                existing_results = []
        
        # TÃ¼m sonuÃ§larÄ± birleÅŸtir (mevcut + yeni)
        all_results = existing_results + results
        
        with open(output_csv, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
            writer.writeheader()
            writer.writerows(all_results)
        
        print(f"\nâœ… SonuÃ§lar CSV'ye kaydedildi: {output_csv}")
        
        # JSON'a da kaydet
        output_json = output_csv.parent / (output_csv.stem + ".json")
        with open(output_json, 'w', encoding='utf-8') as f:
            json.dump({
                "cover_scores": all_results,
                "total_count": len(all_results),
                "last_updated": all_results[-1]["timestamp"] if all_results else None
            }, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… SonuÃ§lar JSON'a kaydedildi: {output_json}")
        
        # Ortalama istatistikleri gÃ¶ster
        valid_results = [r for r in all_results if "error" not in r and "total_score" in r]
        if valid_results:
            # SayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼r
            for r in valid_results:
                if isinstance(r.get("total_score"), str):
                    r["total_score"] = float(r["total_score"])
            avg_score = sum(r["total_score"] for r in valid_results) / len(valid_results)
            print(f"\nğŸ“ˆ Ortalama Toplam Puan: {avg_score:.2f}/10")
            print(f"   Test edilen dosya sayÄ±sÄ±: {len(valid_results)}")
    
    return results


if __name__ == "__main__":
    # Test iÃ§in 3 Ã¶rnek segmentation JSON dosyasÄ±nÄ± bul
    project_root = Path(__file__).resolve().parents[2]
    outputs_dir = project_root / "outputs" / "segmentations"
    
    # .fixed.json dosyalarÄ±nÄ± bul (post-processing sonrasÄ±)
    fixed_files = sorted(outputs_dir.glob("*.fixed.json"), key=lambda p: p.stat().st_mtime, reverse=True)
    
    if len(fixed_files) == 0:
        print(f"âš ï¸  Segmentation dosyasÄ± bulunamadÄ±.")
        print(f"   {outputs_dir} klasÃ¶rÃ¼nde .fixed.json dosyasÄ± olmalÄ±.")
    else:
        # Mevcut dosyalarÄ± al (en fazla 3)
        test_files = fixed_files[:min(3, len(fixed_files))]
        print(f"ğŸ§ª Test edilecek dosyalar:")
        for f in test_files:
            print(f"   - {f.name}")
        
        # CSV Ã§Ä±ktÄ± yolu
        csv_output = project_root / "outputs" / "cover_scores.csv"
        
        # Test Ã§alÄ±ÅŸtÄ±r
        test_multiple_reports(test_files, csv_output)

